# Batchy
#
# Copyright (C) 2019 by its authors (See AUTHORS)
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.

import binascii
import itertools
import scapy.all as scapy
import socket
import struct
import pprint
import sys

mode = get_arg('mode', 'RTC', str)
rounds = get_arg('rounds', 100, int)
control_period = get_arg('control_period', 0.1, float)
controller = get_arg('controller', 'projgradient', str)
src_worker_num = get_arg('src_worker_num', 1, int)

fib_size = get_arg('fib_size', 5000, int)
user_num = get_arg('user_num', 3, int)
bearer_num = get_arg('bearer_num', 2, int)   # bearers per user
bearer0_user = get_arg('bearer0_user', user_num, int)   # users at bearer 0

# rate-limits [bps] and delay bounds
# rate-SLO for bearer 0, rest is proportional
# if not set, then use weights to tune the traffic distribution
rate_slo = get_arg('rate_slo', -1, int)
delay_slo = get_arg('delay_slo', 15_000_000, int)  # for bearer 0, rest is proportional
max_weight = get_arg('max_weight', 4, int)         # max weight for any
bulk_limit = get_arg('bulk_limit', settings.DEFAULT_RATE_LIMIT, int)   # cumulative rate limit on bulk traffic
bulk_limit = {settings.DEFAULT_RATE_LIMIT_RESOURCE: bulk_limit}

# whether pipeline is decomposed to ingress task and per-flow tasks
# 0: whole task is one module
# 1: ingress task(splitters) + per-flow tasks
# 2: QoS task (with all QoS flows) and separate per-bulk tasks
normalized = get_arg('normalized', 0, int)

# bypass parameters
t0_dl = get_arg('t0_dl', 2000, int)
t1_dl = get_arg('t1_dl', 100, int)
t0_ul = get_arg('t0_ul', 2000, int)
t1_ul = get_arg('t1_ul', 100, int)

def aton(ip): return socket.inet_aton(ip)


def mac_from_str(s, mode='bytes'):
    ret = binascii.unhexlify(s.replace(':', ''))
    if mode == 'int':
        ret = int.from_bytes(ret, byteorder='big')
    return ret


def gen_packet(proto, src_ip, dst_ip, src_port=10001, dst_port=10002,
               vxlan_id=None):
    eth = scapy.Ether(src='02:1e:67:9f:4d:ae', dst='ae:34:2e:16:b8:cd')
    ip = scapy.IP(src=src_ip, dst=dst_ip)
    udp = proto(sport=src_port, dport=dst_port)
    payload = 'helloworld'
    if vxlan_id is not None:
        vxeth = scapy.Ether(src='02:1d:61:3f:4d:ae', dst=gw['mac'], type=0x0800)
        vx_ip = scapy.IP(src=src_ip, dst=gw['ip'])
        vxudp = scapy.UDP(sport=4789, dport=4789)
        vxlan = scapy.VXLAN(vni=vxlan_id, flags=0x08)
        pkt = vxeth/vx_ip/vxudp/vxlan/eth/ip/udp/payload
    else:
        pkt = eth/ip/udp/payload
    return bytes(pkt)


def get_octets(seq, offset=11, last=1):
    return (int(seq / 64516) + offset,
            int(seq % 64516 / 254),
            (seq % 254) + 1,
            last)


def get_ip(seq, offset=11, last=1):
    return '.'.join(map(str, get_octets(seq, offset, last)))

# ul:1, dl:0
def get_br_uid(uid, br, dir):
    return uid * bearer_num + br
    # return uid * bearer_num * 2 + br * 2 + (1 if dir == 'ul' else 0) + 1

def get_delay_slo_for_bearer(br, dir):
    return delay_slo * (br+1) if br < bearer_num-1 else None

def get_rate_slo_for_bearer(br, dir):
    if rate_slo < 0:
        return None
    else:
        return {'packet': rate_slo * (br+1)} if br < bearer_num-1 else None

def get_weight_for_bearer(br, dir):
    # return min(int(float(2**br)), 8) if br < bearer_num-1 else 8
    if rate_slo < 0:
        return min(br+1, max_weight) if br < bearer_num-1 else max_weight
    else:
        return 1

vxlan_size = len(scapy.Ether()/scapy.VXLAN()/scapy.IP()/scapy.UDP())

gw = {'ip': '1.10.100.1',
      'mac': 'ac:dc:ac:dc:02:9a'}

em_t0 = 2
em_t1 = 1

ip_t0 = 2
ip_t1 = 1

users = []

for i in range(user_num):
    new_user = {
        'name': f'user_{i}',
        'id': i,
        # 'delay_slo': {'ul': delay_ul,
        #               'dl': delay_dl},
        # 'rate_slo': {'ul': {'bit': rate_ul},
        #              'dl': {'bit': rate_dl}},
        'path': {'ul': {}, 'dl': {}},
        'task': {'ul': {}, 'dl': {}},
        'flow': {'ul': {}, 'dl': {}},
        'ip': {'ul': get_ip(i, offset=10), 'dl': get_ip(i, offset=10)},
        'source_params': {
            'ul': {
                'ts_offset': settings.FLOW_TIMESTAMP_OFFSET + vxlan_size,
                'ts_offset_diff': -vxlan_size,
                'weight': 1,
                'templates': [gen_packet(scapy.UDP,            # per bearer
                                         get_ip(i, offset=10),
                                         get_ip(i, offset=100),
                                         dst_port=1000 + i,
                                         vxlan_id=br) for br in range(bearer_num)]},
            'dl': {
                'ts_offset': settings.FLOW_TIMESTAMP_OFFSET,
                'ts_offset_diff': +vxlan_size,
                'weight': 1,
                'templates': [gen_packet(scapy.UDP,            # per bearer
                                         get_ip(i, offset=100),
                                         get_ip(i, offset=10),
                                         src_port=10 + br,
                                         dst_port=1000 + i) for br in range(bearer_num)]},
        }
    }
    users.append(new_user)

    # for dir in ['dl','ul']:
    #     for bearer, t in enumerate(new_user['source_params'][dir]['templates']):
    #         print(f'-------\n{new_user["name"]}, {bearer}, {dir}\n-----------')
    #         pprint.pprint(scapy.Ether(t).show() )


fib = []
for i in range(user_num):
    dl_entry = {
        'prefix': get_ip(i, offset=10, last=0),
        'prefixlen': 24,
        'ogate': 1,
    }
    fib.append(dl_entry)
    ul_entry = {
        'prefix': get_ip(i, offset=100, last=0),
        'prefixlen': 24,
        'ogate': 0,
    }
    fib.append(ul_entry)
for i in range(fib_size - 2 * user_num):
    dummy_entry = {
        'prefix': get_ip(i, offset=150, last=0),
        'prefixlen': 24,
        'ogate': i % 2,
    }
    fib.append(dummy_entry)


# SET UP PIPELINE
# Step 1: create worker
w0 = batchy.add_worker('w0')

# Step 2: add task to worker
ti = w0.add_task('task_ingress', type=mode)
mtype = 'ingress' if normalized > 0 else 'internal'

for bearer in range(bearer_num):
    for i, user in enumerate(users):
        if bearer == 0 and i >= bearer0_user:
            break
        for dir in ('dl', 'ul'):
            if normalized == 0:
                user['task'][dir][bearer] = ti
            elif normalized == 1:
                t = w0.add_task(f'task_{user["name"]}_{bearer}_{dir}',
                                type=mode)
                user['task'][dir][bearer] = t
            else:
                # qos bearers: ingress task, bulk: own task
                if bearer < bearer_num - 1:
                    user['task'][dir][bearer] = ti
                else:
                    t = w0.add_task(f'task_{user["name"]}_{bearer}_{dir}',
                                    type=mode)
                    user['task'][dir][bearer] = t

# Step 3: add modules to task, set internal pipeline
mac_table = ti.add_module(ExactMatch(name='mac_table',
                                     fields=[{'offset': 0, 'num_bytes': 6}]),
                          type='ingress')
mac_table.module.add(fields=[{'value_bin': mac_from_str('ae:34:2e:16:b8:cd')}],
                     gate=0)
mac_table.module.set_default_gate(gate=0)

type_check = ti.add_module(ExactMatch(name='type_check',
                                      fields=[{'offset': 12, 'num_bytes': 2}]))
type_check.module.add(fields=[{'value_bin': struct.pack('!H', 0x0800)}], gate=0)
type_check.module.set_default_gate(gate=0)
mac_table.connect(type_check)

dir_selector = ti.add_module(ExactMatch(name='dir_selector',
                                        fields=[{'offset': 30, 'num_bytes': 4},    # dst IP
                                                {'offset': 23, 'num_bytes': 1},    # IP proto
                                                {'offset': 36, 'num_bytes': 2}]),  # dst port
                             T_0=em_t0, T_1=em_t1, controlled=False)
dir_selector.module.add(fields=[{'value_bin': aton(gw['ip'])},
                                {'value_bin': struct.pack('B', 17)},
                                {'value_bin': struct.pack('!H', 4789)}],
                        gate=1) # uplink
dir_selector.module.set_default_gate(gate=0) # downlink
type_check.connect(dir_selector)

# in the downlink direction, bearers are selected by TFT/SDF templates, ie,
# fully-fledged 5-tuple packet filters, we substitu these for source port
# based mappings
dl_br_selector = ti.add_module(ExactMatch(name='dl_br_selector',
                                          fields=[{'offset': 34, 'num_bytes': 2}]),  # src port
                               T_0=em_t0, T_1=em_t1, controlled=False)
dl_br_selector.module.set_default_gate(gate=0)
dir_selector.connect(dl_br_selector, ogate=0)

vxlan_decap = ti.add_module(VXLANDecap(name='vxlan_decap'))
# in the uplink direction, bearers are selected by VXLAN/GTP teid
ul_br_selector = ti.add_module(Split(name='ul_br_selector',
                                     attribute='tun_id', size=4))
dir_selector.connect(vxlan_decap, ogate=1)
vxlan_decap.connect(ul_br_selector)

common_path_dl = [mac_table, type_check, dir_selector, dl_br_selector]
common_path_ul = [mac_table, type_check, dir_selector, vxlan_decap, ul_br_selector]

ttl = ti.add_module(UpdateTTL(name=f'update_ttl'))

for bearer in range(bearer_num):
    # dl: src_port
    dl_br_selector.module.add(fields=[{'value_bin': struct.pack("!H", 10 + bearer)}],
                              gate=bearer)
    # ul: tun_id, handled by Split

    # user selectors
    dl_ue_selector = ti.add_module(ExactMatch(name=f'dl_ue_selector_{bearer}',
                                              fields=[{'offset': 30, 'num_bytes': 4}]), # dst IP
                                   T_0=em_t0, T_1=em_t1, controlled=False)
    dl_br_selector.connect(dl_ue_selector, ogate=bearer)

    ul_ue_selector = ti.add_module(ExactMatch(name=f'ul_ue_selector_{bearer}',
                                              fields=[{'offset': 26, 'num_bytes': 4}]), # src IP
                                   T_0=em_t0, T_1=em_t1, controlled=False)
    ul_br_selector.connect(ul_ue_selector, ogate=bearer)

    for i, user in enumerate(users):
        if bearer == 0 and i >= bearer0_user:
            break
        for dir in ('dl', 'ul'):
            selector = dl_ue_selector if dir == 'dl' else ul_ue_selector
            selector.module.add(fields=[{'value_bin': aton(user['ip'][dir])}],
                                gate=user['id'])
            common_path = globals().get(f'common_path_{dir}').copy()
            common_path.append(selector)
            t = user['task'][dir][bearer]
            bp_per_batch = globals().get(f't0_{dir}')
            bp_per_packet = globals().get(f't1_{dir}')

            if normalized == 0:
                type = 'internal'
            elif normalized == 1:
                type = 'ingress'
            else:
                if bearer < bearer_num - 1:
                    type = 'internal'
                else:
                    type = 'ingress'
            bp = t.add_module(Bypass(name=f'{dir}_{user["name"]}_{bearer}_bp',
                                     cycles_per_batch=bp_per_batch,
                                     cycles_per_packet=bp_per_packet),
                              T_0=bp_per_batch/settings.BYPASS_RATIO,
                              T_1=bp_per_packet/settings.BYPASS_RATIO,
                              controlled=True, type=type)
            selector.connect(bp, ogate=user['id'])

            if dir == 'dl':
                md_attrs = [{'name': 'tun_id', 'size': 4,
                             'value_int': user['id']},
                            {'name': 'tun_ip_src', 'size': 4,
                             'value_bin': aton(gw['ip'])},
                            {'name': 'tun_ip_dst', 'size': 4,
                             'value_bin': aton(user['ip']['dl'])},
                            {'name': 'ether_src', 'size': 6,
                             'value_bin': b'\x02\x01\x02\x03\x04\x05'},
                            {'name': 'ether_dst', 'size': 6,
                             'value_bin': b'\x02\x0a\x0b\x0c\x0d\x0e'},
                            {'name': 'uid_br', 'size': 4,
                             'value_bin': get_br_uid(user['id'],
                                                     bearer, dir).to_bytes(4,
                                                     byteorder='big')}]
                # print(get_br_uid(user['id'], bearer, dir).to_bytes(4, byteorder='big'))
                set_md = t.add_module(SetMetadata(name=f'setmd_dl_{user["id"]}_{bearer}',
                                                  attrs=md_attrs))

                vxlan_encap = t.add_module(VXLANEncap(name=f'vxlan_encap_{user["id"]}_{bearer}',
                                                      dstport=1000 + user['id']))
                ip_encap = t.add_module(IPEncap(name=f'ip_encap_{user["id"]}_{bearer}'))
                eth_encap = t.add_module(EtherEncap(name=f'ether_encap_{user["id"]}_{bearer}'))

                bp.connect(set_md)
                set_md.connect(vxlan_encap)
                vxlan_encap.connect(ip_encap)
                ip_encap.connect(eth_encap)
                eth_encap.connect(ttl)

                path = [bp, set_md, vxlan_encap, ip_encap, eth_encap]
                common_path.append(dl_ue_selector)
            else:
                md_attrs = [{'name': 'uid_br', 'size': 4,
                             'value_bin': get_br_uid(user['id'],
                                            bearer, dir).to_bytes(4,
                                            byteorder='big')}]
                set_md = t.add_module(SetMetadata(name=f'setmd_ul_{user["id"]}_{bearer}',
                                                  attrs=md_attrs))
                bp.connect(set_md)
                set_md.connect(ttl)
                path = [ul_ue_selector, bp, set_md]
                common_path.append(ul_ue_selector)

            if normalized == 0:
                user['path'][dir][bearer] = [{'task': ti,
                                              'path': common_path + path}]
            elif normalized == 1:
                user['path'][dir][bearer] = [{'task': ti, 'path': common_path},
                                             {'task': t, 'path': path}]
            else:
                if bearer < bearer_num - 1:
                    user['path'][dir][bearer] = [{'task': ti,
                                                  'path': common_path + path}]
                else:
                    user['path'][dir][bearer] = [{'task': ti, 'path': common_path},
                                                 {'task': t, 'path': path}]

# these all go to the ingress task
l3 = ti.add_module(IPLookup(name='L3', max_rules=fib_size),
                   T_0=ip_t0, T_1=ip_t1)
ttl.connect(l3)
for entry in fib:
    l3.module.add(prefix=entry['prefix'],
                  prefix_len=entry['prefixlen'],
                  gate=entry['ogate'])

nhops = {'ul': {'smac': 'aa:bb:bb:aa:ac:dc',
                'dmac': 'ee:dd:dd:aa:01:01',
                'ogate': 0,
                'path': None},
         'dl': {'smac': 'aa:bb:bb:aa:ac:dc',
                'dmac': 'ee:dd:dd:aa:02:02',
                'ogate': 1,
                'path': None}}
for dir, cfg in nhops.items():
    src_mac = mac_from_str(cfg['smac'], mode='int')
    dst_mac = mac_from_str(cfg['dmac'], mode='int')
    mac = ti.add_module(Update(name=f'update_mac_{dir}',
                               fields=[{'offset': 6, 'size': 6,
                                        'value': src_mac},
                                       {'offset': 0, 'size': 6,
                                        'value': dst_mac}]))
    chk = ti.add_module(IPChecksum(name=f'ip_checksum_{dir}'))
    # flow_demuxer = te.add_module(ExactMatch(name=f'flow_demuxer_{dir}',
    #                                         fields=[{'offset': 36,
    #                                                  'num_bytes': 2}]),  # dst port
    #                              T_0=em_t0, T_1=em_t1, controlled=False)
    flow_demuxer = ti.add_module(Split(name=f'flow_demuxer_{dir}',
                                       attribute='uid_br', size=4))
    l3.connect(mac, ogate=cfg['ogate'])
    mac.connect(chk)
    chk.connect(flow_demuxer)
    cfg['path'] = [ttl, l3, mac, chk, flow_demuxer]

    for bearer in range(bearer_num):
        for i, user in enumerate(users):
            if bearer == 0 and i >= bearer0_user:
                break
            dmux_bp = ti.add_module(Bypass(name=f'demux_bp_{dir}_{user["name"]}_{bearer}'))
            flow_demuxer.connect(dmux_bp, ogate=get_br_uid(user['id'], bearer, dir))
            # append the egress pipeline to each flow's last taskflow (ugly)
            user['path'][dir][bearer][-1]['path'].extend(cfg['path'] + [dmux_bp])

# Step 4: add flows
for bearer in range(bearer_num):
    for i, user in enumerate(users):
        if bearer == 0 and i >= bearer0_user:
            break
        for dir in ('dl', 'ul'):
            if not normalized:
                path = list(itertools.chain(*((v['path'] for v in user['path'][dir][bearer]))))
                user['path'][dir][bearer] = [{'task': ti, 'path': path}]
            src_br = user['source_params'][dir].copy()
            src_br['templates'] = [src_br['templates'][bearer]]
            src_br['weight'] = get_weight_for_bearer(bearer, dir)
            src_br['burst_size'] = 1 # relevant only for non-bulk
            src_br['ts_offset'] = user['source_params'][dir]['ts_offset']
            new_flow = batchy.add_flow(name=f'{user["name"]}_{bearer}_{dir}',
                                       path=user['path'][dir][bearer],
                                       delay_slo=get_delay_slo_for_bearer(bearer, dir),
                                       rate_slo=get_rate_slo_for_bearer(bearer, dir),
                                       source_params=src_br)
            user['flow'][dir][bearer] = new_flow

# Step 5: add test traffic
for i in range(src_worker_num):
    src_worker_name = f'src_{i}'
    src_worker = batchy.add_worker(src_worker_name)
    src_worker.set_bulk_ratelimit(bulk_limit)
    for dir in ('dl', 'ul'):
        ts_offset = users[0]['source_params'][dir]['ts_offset']

        if rate_slo < 0:
            # not rate limitation, add everything as bulk
            batchy.add_bulk_source([f for f in batchy.flows if dir in f.name],
                                   src_worker, postfix=dir, ts_offset=ts_offset)
        else:
            # add QoS flows for everything except the last bearer (bulk)
            bulk_flows = []
            qos_flows = []
            for user in users:
                for user in users:
                    for _, uflow in user['flow'][dir].items():
                        if flow.has_rate_slo():
                            qos_flows.append(uflow)
                        else:
                            bulk_flows.append(uflow)
            if qos_flows:
                batchy.add_qos_source(qos_flows, src_worker, postfix=dir,
                                      ts_offset=ts_offset)
            if bulk_flows:
                batchy.add_bulk_source(bulk_flows, src_worker, postfix=dir,
                                       ts_offset=ts_offset)

batchy.add_sink()

# Step 6: set controller for worker
controller_name = batchy.resolve_task_controller(controller)
ti.set_controller(controller_name)
if normalized > 0:

    for bearer in range(bearer_num):
        for i, user in enumerate(users):
            if bearer == 0 and i >= bearer0_user:
                break
            for dir in ('dl', 'ul'):
                t = user['task'][dir][bearer]
                t.set_controller(controller_name)

# Step 7: run pipeline
batchy.run(rounds, control_period)
basename = f'mgw_{mode}_{controller}_norm_{normalized}'
batchy.dump(f'/tmp/{basename}.txt')
batchy.plot(f'/tmp/{basename}.png')

#bess.resume_all()
#bess.reset_all()
